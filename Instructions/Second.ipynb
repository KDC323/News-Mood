{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Mood\n",
    "\n",
    "In this assignment, you'll create a Python script to perform a sentiment analysis of the Twitter activity of various news oulets, and to present your findings visually.\n",
    "\n",
    "Your final output should provide a visualized summary of the sentiments expressed in Tweets sent out by the following news organizations: __BBC, CBS, CNN, Fox, and New York times__.\n",
    "\n",
    "![output_10_0.png](output_10_0.png)\n",
    "\n",
    "![output_13_1.png](output_13_1.png)\n",
    "\n",
    "The first plot will be and/or feature the following:\n",
    "\n",
    "* Be a scatter plot of sentiments of the last __100__ tweets sent out by each news organization, ranging from -1.0 to 1.0, where a score of 0 expresses a neutral sentiment, -1 the most negative sentiment possible, and +1 the most positive sentiment possible.\n",
    "* Each plot point will reflect the _compound_ sentiment of a tweet.\n",
    "* Sort each plot point by its relative timestamp.\n",
    "\n",
    "The second plot will be a bar plot visualizing the _overall_ sentiments of the last 100 tweets from each organization. For this plot, you will again aggregate the compound sentiments analyzed by VADER.\n",
    "\n",
    "The tools of the trade you will need for your task as a data analyst include the following: tweepy, pandas, matplotlib, seaborn, textblob, and VADER.\n",
    "\n",
    "Your final Jupyter notebook must:\n",
    "\n",
    "* Pull last 100 tweets from each outlet.\n",
    "* Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet. \n",
    "* Pull into a DataFrame the tweet's source acount, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "* Export the data in the DataFrame into a CSV file.\n",
    "* Save PNG images for each plot.\n",
    "\n",
    "As final considerations:\n",
    "\n",
    "* Use the Matplotlib and Seaborn libraries.\n",
    "* Include a written description of three observable trends based on the data. \n",
    "* Include proper labeling of your plots, including plot titles (with date of analysis) and axes labels.\n",
    "* Include an exported markdown version of your Notebook called  `README.md` in your GitHub repository.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "import time\n",
    "import datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = \"IqqOcoOSlCxcEUAuZQY1Kb02L\"\n",
    "consumer_secret = \"4ISKPBgy56BXsp7a8Ja639ToJ9xhjeAya13yg3bRU7wnfkL9f3\"\n",
    "access_token = \"922955283172876289-OK82xypOTTZsmZnsG2sxZxjVC9wlymW\"\n",
    "access_token_secret = \"zyJNP5AaGcAuKuKiNEWiUwiBccWdEWrMawvksujYJigq3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_outlet = [\"@BBC\", \"@CBS\", \"@CNN\", \"@Fox\", \"@nytimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables for holding sentiments\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables for DataFrame\n",
    "media_sources = []\n",
    "text = []\n",
    "date = []\n",
    "tweets_ago = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looping through all the users\n",
    "for outlet in news_outlet:\n",
    "    \n",
    "    # Tweet count\n",
    "    tweet_count = 0\n",
    "\n",
    "    # Get the last 100 tweets\n",
    "    for x in range(5):\n",
    "        # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(outlet, page=x)\n",
    "\n",
    "        # Loop through all the tweets\n",
    "        for tweet in public_tweets:\n",
    "        \n",
    "            # Incrementing tweet_count\n",
    "            tweet_count += 1\n",
    "    \n",
    "            # Adding values to list\n",
    "            media_sources.append(outlet)\n",
    "            text.append(tweet['text'])\n",
    "            date.append(tweet['created_at'])\n",
    "            tweets_ago.append(tweet_count)\n",
    "    \n",
    "            # Run Vader Analysis on each tweet\n",
    "            compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "            neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "            \n",
    "            # Add each value to the appropriate list\n",
    "            compound_list.append(compound)\n",
    "            positive_list.append(pos)\n",
    "            neutral_list.append(neu)\n",
    "            negative_list.append(neg)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the DataFrame\n",
    "TweetData = pd.DataFrame({\"Media Source\": media_sources, \"Tweet\": text, \"Date & Time (UTC)\": date,\n",
    "    \"Compound Score\": compound_list, \"Positive Score\": positive_list,\n",
    "    \"Neutral Score\": neutral_list, \"Negative Score\": negative_list,\n",
    "    \"Tweets Ago\": tweets_ago})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
